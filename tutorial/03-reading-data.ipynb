{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98b117c8-51b2-4a7c-acac-5db439945586",
   "metadata": {},
   "source": [
    "# Tutorial 3: Connecting to Your Data Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd606f0d-37ba-4f91-9514-41653e6482cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os; os.chdir(\"..\")\n",
    "import credential\n",
    "import ponder.snowflake\n",
    "import modin.pandas as pd\n",
    "snowflake_con = ponder.snowflake.connect(user=credential.params[\"user\"],password=credential.params[\"password\"],account=credential.params[\"account\"],role=credential.params[\"role\"],database=credential.params[\"database\"],schema=credential.params[\"schema\"],warehouse=credential.params[\"warehouse\"])\n",
    "ponder.snowflake.init(snowflake_con,enable_ssl=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90cd1e5e-fd2b-4b04-9a3b-a0bf5be06240",
   "metadata": {},
   "source": [
    "Before we start can start our analysis, we need to first connect to a data source. Ponder currently supports `read_csv` for operating on CSV files and `read_sql` for operating on tables that are already stored in Snowflake."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2caaf89-7c98-47d6-b4b1-e7dc07318762",
   "metadata": {},
   "source": [
    "<img src=\"https://docs.ponder.io/_images/architecture.png\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511071e4-0121-45fc-8fe0-6574609f61b5",
   "metadata": {},
   "source": [
    "## ``read_sql:``Working with existing tables\n",
    "\n",
    "To work with data stored in an existing table in Snowflake, we use the ``read_sql`` command and provide the name of the table ``PONDER_CUSTOMER`` and pass in ``auto`` to the connection parameter to auto-populate the connection information based on what we provided earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c3f33a-c621-4bf1-b2c2-01b05531fb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql(\"PONDER_CUSTOMER\", snowflake_con)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8c4d0e-c38b-4f62-a87f-8155ac869dfc",
   "metadata": {},
   "source": [
    "Now that we have a Ponder DataFrame that points to the ``PONDER_CUSTOMER`` table in your data warehouse, you can now work on your DataFrame ``df`` just like you would typically do with any pandas dataframe – with all the computation happening on your warehouse!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3a73e8-54e8-4ff8-bdcd-6ade394e33ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fadeace-bb12-4ba2-82a5-f205b30cc39e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> <b>Note: </b> <span> Unlike in pandas, the data ingestion (read_*) command in Ponder does not actually load in the data into a dataframe in memory. Instead, you can think of the Ponder DataFrame acting as a pointer to the table in Snowflake that stores the data and relays all the operations to be performed on the tables in Snowflake. </span></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e41980-4ecc-4b0a-abd2-14ddd66c6724",
   "metadata": {},
   "source": [
    "## ``read_csv:`` Working with CSV files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafb3e0e-4ed0-4b7b-a62f-2512689b6a5f",
   "metadata": {},
   "source": [
    "### Working with remote CSV files\n",
    "To work with ``CSV`` files, use the ``read_csv`` command to feed in the filepath to the CSV file. If the filepath is a remote path to the CSV (e.g., filepath to S3, GCS, or a public dataset URL), you can enter the path directly as follow. Ponder will automatically process your CSV file and load it into a temporary table in your data warehouse account for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c727d98-c1e2-4065-8243-dc723c908a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/ponder-org/ponder-datasets/main/orders.csv\", header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96659862-0482-440f-a433-a81270e92d50",
   "metadata": {},
   "source": [
    "Now that your data is loaded into a temporary table in your data warehouse and Ponder DataFrame is pointing to the table, you can now work on your DataFrame ``df`` just like you would typically do with any pandas dataframe – with all the computation happening on your warehouse!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d68d5ff-8b4c-424d-a761-8afe347276fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ad8d30-a5bc-48f4-ae39-e15743bc6742",
   "metadata": {},
   "source": [
    "### Working with your own local CSV files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aceb50df-7f41-48b1-9cf7-08e1173346f0",
   "metadata": {},
   "source": [
    "If you have a CSV file locally that you want to analyze with Ponder, we provide an interface that allows you to stage the file for analysis.\n",
    "\n",
    "**1. Uploading to Ponder:** If you have a CSV file on your local machine, you must first upload them through the notebook interface. You can upload files to your Jupyter directory using the file upload functionality provided by Jupyter notebook.\n",
    "\n",
    "<img src=\"https://docs.ponder.io/_images/upload2.png\" width=\"50%\"></img>\n",
    "\n",
    "**2. Staging CSV file to a remote path:** After uploading your files to the Jupyter directory, you will need to stage the file to a remote path so that it is accessible by read_csv, as following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7bee4ea-8c92-4426-a34a-fbd34206b696",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: wget\n"
     ]
    }
   ],
   "source": [
    "!wget -q \"https://raw.githubusercontent.com/ponder-org/ponder-datasets/main/movies.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8563d4f-4253-4ed7-b58b-57717dfa3b33",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 36626  100 36626    0     0   398k      0 --:--:-- --:--:-- --:--:--  441k\n"
     ]
    }
   ],
   "source": [
    "!curl \"https://raw.githubusercontent.com/ponder-org/ponder-datasets/main/movies.csv\" > movies.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d863b9cd-40ba-4a81-8a7d-8f9c0b5819c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-13 20:30:46,382 - depulso - INFO - Compression took 0.002811908721923828s\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'NoneType' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mponder\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Teleporter\n\u001b[1;32m      2\u001b[0m t \u001b[38;5;241m=\u001b[39m Teleporter()\n\u001b[0;32m----> 3\u001b[0m remote_path \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdepulso\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmovies.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/dev2/lib/python3.10/site-packages/ponder/utils/core.py:102\u001b[0m, in \u001b[0;36mTeleporter.depulso\u001b[0;34m(self, filepath, parent, remote_chunksize)\u001b[0m\n\u001b[1;32m    100\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompression took \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;241m-\u001b[39mstart\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m, extra\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextra_dict)\n\u001b[1;32m    101\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 102\u001b[0m remote_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mteleported_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocal_compressed_filepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEstablishing connection to remot host\u001b[39m\u001b[38;5;124m\"\u001b[39m, extra\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextra_dict)\n\u001b[1;32m    104\u001b[0m config \u001b[38;5;241m=\u001b[39m rpyc\u001b[38;5;241m.\u001b[39mcore\u001b[38;5;241m.\u001b[39mprotocol\u001b[38;5;241m.\u001b[39mDEFAULT_CONFIG\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[0;32m~/.virtualenvs/dev2/lib/python3.10/site-packages/ponder/utils/core.py:145\u001b[0m, in \u001b[0;36mTeleporter.teleported_path\u001b[0;34m(self, filepath, parent)\u001b[0m\n\u001b[1;32m    141\u001b[0m         parent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(pathlib\u001b[38;5;241m.\u001b[39mPath()\u001b[38;5;241m.\u001b[39mabsolute() \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdepulso\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    143\u001b[0m         \u001b[38;5;66;03m# TODO: Change token to username or similar.\u001b[39;00m\n\u001b[1;32m    144\u001b[0m         \u001b[38;5;66;03m# In deployment(efs) /data is the only mount client can write to\u001b[39;00m\n\u001b[0;32m--> 145\u001b[0m         parent \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/data/tmp/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mUtilsConnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_token\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43msecrets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoken_urlsafe\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    146\u001b[0m parent \u001b[38;5;241m=\u001b[39m parent \u001b[38;5;28;01mif\u001b[39;00m (parent \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m parent\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m platform\u001b[38;5;241m.\u001b[39msystem() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwin32\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'NoneType' and 'str'"
     ]
    }
   ],
   "source": [
    "from ponder.utils.core import Teleporter\n",
    "t = Teleporter()\n",
    "remote_path = t.depulso(\"movies.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c66eba-a566-45d0-b334-5609a71ba88f",
   "metadata": {},
   "source": [
    "**3. Read your CSV file with ``read_csv``**: Once the file is staged to the remote_path, you can load it in via `pd.read_csv` as usual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1f7bad-29ec-4578-8f08-5a7be51783c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(remote_path, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be633e30-bb1d-4ac9-8873-0a155c692f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
