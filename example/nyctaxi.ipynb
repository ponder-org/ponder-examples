{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff4043e6-7c0a-4f4e-a44c-4c46daf17fa7",
   "metadata": {},
   "source": [
    "In this example, we would like to work with a subset of **\"Taxi cab\"** dataset stored in a csv file. Taxi cab dataset shows yellow taxi trip data in New York city. \n",
    "\n",
    "This dataset includes fields capturing pick-up and drop-off dates/times, pick-up and drop-off locations, trip distances, itemized fares, rate types, payment types, and driver-reported passenger counts.\n",
    "\n",
    "This data set contains 210035 rows and 20 columns. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17434cd3-68b6-4ce4-af4a-58bd2ac43777",
   "metadata": {},
   "source": [
    "### Initialize the connection\n",
    "To use Ponder, we first need to initialize Ponder Snowflake connection. Please find more instruction on how initialize the connection between Ponder and Snowflake here (https://docs.ponder.io/getting_started/quickstart.html#step-3-connect-to-snowflake)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e77af12-8a6e-45eb-8edb-96f4b732edd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import modin.pandas as pd\n",
    "import ponder.snowflake\n",
    "from ponder.utils.core import Teleporter\n",
    "\n",
    "snowflake_con = ponder.snowflake.connect(user=*****, password=*****, account=*****, role=*****, database=*****, schema=*****, warehouse=*****)\n",
    "\n",
    "ponder.snowflake.init(snowflake_con, timeout=1200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c618b328-8736-40c3-8504-0ac7c5f53ec4",
   "metadata": {},
   "source": [
    "We first read the **\"yellow_tripdata_2015-01.csv\"** file using **read_csv** command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f299199-a4b6-47fe-89d1-7b33b9b9d81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/ponder-org/ponder-datasets/main/yellow_tripdata_2015-01.csv\", header=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a4a6c4-be67-473e-94f4-4288309a861d",
   "metadata": {},
   "source": [
    "Looking at the columns of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2e6af1-1528-48cc-aa88-44b8c6f02ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046e5a30-b088-490f-8de9-3de238a82bb0",
   "metadata": {},
   "source": [
    "Next, we are going to drop some of the uncessary columns since we are not going to use them during our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7d5280-b9e0-430b-b427-af82200224fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df.drop(columns=['FARE_AMOUNT', 'STORE_AND_FWD_FLAG','RATECODEID','AIRPORT_FEE',' '])\n",
    "df_cleaned.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee6f847-d7c3-468b-acc2-2fd3544a4608",
   "metadata": {},
   "source": [
    "Looking at the PAYMENT_TYPE attribute in our dataframe, we notice that payment type values (e.g., credit card, cash, etc) are represented using numerical values (e.g., 1, 2, etc). We replace these numerical values with their corresponding payment types to make the dataframe more readable. To do this: <br> - We need to change the 'PAYMENT_TYPE' variable type from integer to string. <br> - We then need to replace the numerical values with their string equivalent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c66b9e2-d024-4e62-acaf-edf0e06ca663",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned['PAYMENT_TYPE'] = df_cleaned['PAYMENT_TYPE'].astype(str)\n",
    "df_cleaned['PAYMENT_TYPE'] = df_cleaned['PAYMENT_TYPE'].replace(['1', '2', '3', '4', '5', '6'], ['credit card', 'cash', 'No charge', 'Dispute' ,'Unknown', 'voided trip'])\n",
    "df_cleaned['PAYMENT_TYPE'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4982e05-146a-4169-bfbb-a312b1177fa3",
   "metadata": {},
   "source": [
    "Next, to get a better sense of our data we at dimensionality and descriptive statistics of our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440db446-816f-4b5f-9097-396da43eb395",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd8e4cc-9dd4-436a-aa10-fc37335f213c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00944713-7e38-4c87-89c8-f6849556b69b",
   "metadata": {},
   "source": [
    "We use isna command to detect the number of missing values in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080a35ea-3aee-42b4-bd9f-4c1693e39bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5ab923-6199-48aa-acd6-6cfe50716ba0",
   "metadata": {},
   "source": [
    "One of our main questions that we have is to investigate the distribution of passengers (\"PASSENGER_COUNT\") per trip. To answer this question, we groupby PASSENGER_COUNT and get the size of each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7a2531-216c-4a89-a2dd-b7f0a9e0c91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.groupby(['PASSENGER_COUNT']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07625507-60a8-4bad-ac03-52d0d16bd029",
   "metadata": {},
   "source": [
    "We notice that most of the trips have one or two passengers, so we focus on this subset of data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255fb833-eaf1-439a-9a45-f9bff27c4591",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df_cleaned.loc[(df_cleaned['PASSENGER_COUNT'] >= 1) & (df_cleaned['PASSENGER_COUNT'] <= 2)]\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15aadef-8868-4576-a628-015c4d2044bf",
   "metadata": {},
   "source": [
    "Now that we filtered out all trips that are not one or two passengers, we want to know what is the longest and shortest trip distance for this subset of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7d7ce6-d7db-4769-9914-c873c84bf30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "longest= df2.nlargest(1,'TRIP_DISTANCE')\n",
    "shortest = df2.nsmallest(1,'TRIP_DISTANCE')\n",
    "print(longest, shortest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e7c430-e25d-4c8d-9250-f0d4d1989eab",
   "metadata": {},
   "source": [
    "Finally, we would like to see the most common payment methods in these trips. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01450cf9-a207-4d33-b80f-3dfce0147257",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.groupby(['PAYMENT_TYPE']).size()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
