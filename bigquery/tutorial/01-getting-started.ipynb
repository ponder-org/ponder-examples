{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57c6b83b-d5e8-47f6-81b9-d2c4761ae9e8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Tutorial 1: Getting Started\n",
    "\n",
    "In this tutorial, we will walk through how you can get started running pandas on BigQuery using Ponder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1619cf-c5c4-48b6-bcef-bb40820dd8ea",
   "metadata": {},
   "source": [
    "### BigQuery Connections Credential"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9d5d76-4861-4c35-816a-9ba02cfe5f6e",
   "metadata": {},
   "source": [
    "To run Ponder on your data warehouse, you must first establish database connection to your warehouse. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4305e08-36a0-4d82-9dea-63ad81d106ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "creds = json.load(open(os.path.expanduser(\"/Users/dorislee/Desktop/access_keys/doris-bigquery-381416-497e94001f15.json\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed59fe47-7e6a-49e5-ab5d-be9f08e9704b",
   "metadata": {},
   "source": [
    "### Connecting to BigQuery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e111fd-481d-4d9b-b3de-65c6f654e5e0",
   "metadata": {},
   "source": [
    "Ponder uses your data warehouse as an engine, so we need to establish a connection with BigQuery in order to start querying the data. The code below shows how you can configure the database connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5daff59e-6b88-4458-a070-3f29a5c39d18",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-22 11:13:35,659 - INFO - Establishing connection to service.ponder.io\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection encrypted with TLSv1.3\n",
      "Connected to\n",
      "       ___               __\n",
      "      / _ \\___  ___  ___/ /__ ____\n",
      "     / ___/ _ \\/ _ \\/ _  / -_) __/\n",
      "    /_/___\\___/_//_/\\_,_/\\__/_/\n",
      "      / __/__ _____  _____ ____\n",
      "     _\\ \\/ -_) __/ |/ / -_) __/\n",
      "    /___/\\__/_/  |___/\\__/_/\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import ponder.bigquery\n",
    "\n",
    "# Create a Ponder BigQuery Connections object\n",
    "bigquery_con = ponder.bigquery.connect(creds, schema = \"TEST\")\n",
    "\n",
    "# Initialize the BigQuery connection\n",
    "ponder.bigquery.init(bigquery_con,enable_ssl=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1befaf78-c3fc-463a-becc-190c64e7ff73",
   "metadata": {},
   "source": [
    "If you have succesfully established the connection, you should see the following output"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9eccd7be-c688-44ce-b724-676c319d29dd",
   "metadata": {},
   "source": [
    "Connected to\n",
    "       ___               __\n",
    "      / _ \\___  ___  ___/ /__ ____\n",
    "     / ___/ _ \\/ _ \\/ _  / -_) __/\n",
    "    /_/___\\___/_//_/\\_,_/\\__/_/\n",
    "      / __/__ _____  _____ ____\n",
    "     _\\ \\/ -_) __/ |/ / -_) __/\n",
    "    /___/\\__/_/  |___/\\__/_/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbee2f6-ad70-4b3e-a0cf-3d7bae33264f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Uploading Example Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4d896b-2c19-4b7c-97bf-426041a31d63",
   "metadata": {},
   "source": [
    "We will be using a few example datasets for the tutorial. You can run this python script to populate the required datasets to your database. This will add three different tables to your database populated with example datasets: \n",
    "- [PONDER_TAXI](https://raw.githubusercontent.com/ponder-org/ponder-datasets/main/yellow_tripdata_2015-01.csv)\n",
    "- [PONDER_CITIBIKE](https://raw.githubusercontent.com/ponder-org/ponder-datasets/main/citibike_trial.csv)\n",
    "- [PONDER_BOOK](https://github.com/ponder-org/ponder-datasets/blob/main/books.csv).\n",
    "\n",
    "Note that you only need to run the following script once for the tables to get populated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0da0037e-d2fa-4943-bc86-8835bd56dbce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !python populate_datasets.py > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0274eb-36b8-47ea-9110-bbd802d0643e",
   "metadata": {},
   "source": [
    "### Starting Pondering ðŸŽ‰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82a1849-d53c-4c63-a31e-747445fabec2",
   "metadata": {},
   "source": [
    "Now that we have the connection initialized. Let's read the **PONDER_CUSTOMER** table that already exists in your database. This dataset is a sample of the `CUSTOMER` table in the [TPCH dataset](https://www.tpc.org/tpch/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8797cd9c-e2b0-4589-8f60-8583e1347b1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import modin.pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6f7737dd-03ae-4b6f-aeaf-378609b9d5d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_sql(\"PONDER_CUSTOMER\", bigquery_con)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a74a49-45b5-4070-ace6-5b36f6edadad",
   "metadata": {},
   "source": [
    "Let's first print out the dataframe and take a look at the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0fab392c-75d4-4a3b-b0b7-f16f72205ba5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>O_ORDERKEY</th>\n",
       "      <th>O_CUSTKEY</th>\n",
       "      <th>O_ORDERSTATUS</th>\n",
       "      <th>O_TOTALPRICE</th>\n",
       "      <th>O_ORDERDATE</th>\n",
       "      <th>O_ORDERPRIORITY</th>\n",
       "      <th>O_CLERK</th>\n",
       "      <th>O_SHIPPRIORITY</th>\n",
       "      <th>O_COMMENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>888608</td>\n",
       "      <td>60047</td>\n",
       "      <td>F</td>\n",
       "      <td>121724.69</td>\n",
       "      <td>9/30/1992</td>\n",
       "      <td>5-LOW</td>\n",
       "      <td>Clerk#000000326</td>\n",
       "      <td>0</td>\n",
       "      <td>express packages boost slyly quickly bold asy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1050464</td>\n",
       "      <td>60040</td>\n",
       "      <td>F</td>\n",
       "      <td>320535.89</td>\n",
       "      <td>1/27/1993</td>\n",
       "      <td>5-LOW</td>\n",
       "      <td>Clerk#000000646</td>\n",
       "      <td>0</td>\n",
       "      <td>s dolphins are carefully at the quickly iron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>246241</td>\n",
       "      <td>60028</td>\n",
       "      <td>F</td>\n",
       "      <td>19117.05</td>\n",
       "      <td>5/30/1992</td>\n",
       "      <td>5-LOW</td>\n",
       "      <td>Clerk#000000711</td>\n",
       "      <td>0</td>\n",
       "      <td>ly among the quickly silent p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>162594</td>\n",
       "      <td>60049</td>\n",
       "      <td>F</td>\n",
       "      <td>27063.41</td>\n",
       "      <td>3/16/1992</td>\n",
       "      <td>5-LOW</td>\n",
       "      <td>Clerk#000000949</td>\n",
       "      <td>0</td>\n",
       "      <td>nts use furiously. quickly regular accounts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>859619</td>\n",
       "      <td>60020</td>\n",
       "      <td>F</td>\n",
       "      <td>191464.85</td>\n",
       "      <td>8/16/1994</td>\n",
       "      <td>5-LOW</td>\n",
       "      <td>Clerk#000000171</td>\n",
       "      <td>0</td>\n",
       "      <td>pinto beans breach. f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>916005</td>\n",
       "      <td>60067</td>\n",
       "      <td>P</td>\n",
       "      <td>93197.61</td>\n",
       "      <td>3/20/1995</td>\n",
       "      <td>2-HIGH</td>\n",
       "      <td>Clerk#000000349</td>\n",
       "      <td>0</td>\n",
       "      <td>eposits are across the slyly ironic instructio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>919652</td>\n",
       "      <td>60100</td>\n",
       "      <td>P</td>\n",
       "      <td>237607.25</td>\n",
       "      <td>5/9/1995</td>\n",
       "      <td>2-HIGH</td>\n",
       "      <td>Clerk#000000052</td>\n",
       "      <td>0</td>\n",
       "      <td>. carefully furious excuses according to th</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>219908</td>\n",
       "      <td>60052</td>\n",
       "      <td>P</td>\n",
       "      <td>88290.20</td>\n",
       "      <td>3/29/1995</td>\n",
       "      <td>1-URGENT</td>\n",
       "      <td>Clerk#000000487</td>\n",
       "      <td>0</td>\n",
       "      <td>he unusual packages. regular platelets use car...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>668835</td>\n",
       "      <td>60089</td>\n",
       "      <td>P</td>\n",
       "      <td>326256.63</td>\n",
       "      <td>5/9/1995</td>\n",
       "      <td>3-MEDIUM</td>\n",
       "      <td>Clerk#000000721</td>\n",
       "      <td>0</td>\n",
       "      <td>he slyly ironic packages inte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>244579</td>\n",
       "      <td>60085</td>\n",
       "      <td>P</td>\n",
       "      <td>159397.20</td>\n",
       "      <td>6/11/1995</td>\n",
       "      <td>4-NOT SPECIFIED</td>\n",
       "      <td>Clerk#000000404</td>\n",
       "      <td>0</td>\n",
       "      <td>realms haggle blithely slyly permanent ideas. ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>145 rows x 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     O_ORDERKEY  O_CUSTKEY O_ORDERSTATUS  O_TOTALPRICE O_ORDERDATE  \\\n",
       "0        888608      60047             F     121724.69   9/30/1992   \n",
       "1       1050464      60040             F     320535.89   1/27/1993   \n",
       "2        246241      60028             F      19117.05   5/30/1992   \n",
       "3        162594      60049             F      27063.41   3/16/1992   \n",
       "4        859619      60020             F     191464.85   8/16/1994   \n",
       "..          ...        ...           ...           ...         ...   \n",
       "140      916005      60067             P      93197.61   3/20/1995   \n",
       "141      919652      60100             P     237607.25    5/9/1995   \n",
       "142      219908      60052             P      88290.20   3/29/1995   \n",
       "143      668835      60089             P     326256.63    5/9/1995   \n",
       "144      244579      60085             P     159397.20   6/11/1995   \n",
       "\n",
       "     O_ORDERPRIORITY          O_CLERK  O_SHIPPRIORITY  \\\n",
       "0              5-LOW  Clerk#000000326               0   \n",
       "1              5-LOW  Clerk#000000646               0   \n",
       "2              5-LOW  Clerk#000000711               0   \n",
       "3              5-LOW  Clerk#000000949               0   \n",
       "4              5-LOW  Clerk#000000171               0   \n",
       "..               ...              ...             ...   \n",
       "140           2-HIGH  Clerk#000000349               0   \n",
       "141           2-HIGH  Clerk#000000052               0   \n",
       "142         1-URGENT  Clerk#000000487               0   \n",
       "143         3-MEDIUM  Clerk#000000721               0   \n",
       "144  4-NOT SPECIFIED  Clerk#000000404               0   \n",
       "\n",
       "                                             O_COMMENT  \n",
       "0     express packages boost slyly quickly bold asy...  \n",
       "1         s dolphins are carefully at the quickly iron  \n",
       "2                        ly among the quickly silent p  \n",
       "3         nts use furiously. quickly regular accounts   \n",
       "4                                pinto beans breach. f  \n",
       "..                                                 ...  \n",
       "140  eposits are across the slyly ironic instructio...  \n",
       "141        . carefully furious excuses according to th  \n",
       "142  he unusual packages. regular platelets use car...  \n",
       "143                      he slyly ironic packages inte  \n",
       "144  realms haggle blithely slyly permanent ideas. ...  \n",
       "\n",
       "[145 rows x 9 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb9f61c-798c-44c0-b3a3-02b0ccab8d10",
   "metadata": {},
   "source": [
    "Now we can start hacking away with pandas! Note that every single operations you are doing here with pandas is directly being run on BigQuery."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c0962d-4af0-4eb0-84ed-7f9acc04bee3",
   "metadata": {},
   "source": [
    "First, let's take a look at the basic statistics around the numerical columns in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799f256e-f8df-4200-98ae-2d6d8b9144e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48aecf38-8090-4b74-b7e3-a4964a6e5410",
   "metadata": {},
   "source": [
    "Let's say we want to normalize the numerical columns by doing a standard z-score normalization (where $\\mu$ is the mean and $\\sigma$ is the standard deviation). \n",
    "\n",
    "$$ x' = \\frac{x-\\mu}{\\sigma}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a028cf8e-c887-4ee4-aabb-66e5b80ea1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.select_dtypes(include='number').columns\n",
    "(df[x] - df[x].mean())/df[x].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83575259-23e6-4d80-bb0f-ec43b2a7d35d",
   "metadata": {},
   "source": [
    "Next, let's look at all the columns that are non-numerical:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458322f6-d045-44e5-8880-218c1b179764",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select_dtypes(include='object').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb131dc-8ded-4fe6-8294-383a8b4e729d",
   "metadata": {},
   "source": [
    "We can look at the number of distinct value in each of these non-numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1797fd3-0523-47b2-8c36-aec684d6d173",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select_dtypes(include='object').nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782c2dda-9f85-4852-9555-b0018a658388",
   "metadata": {},
   "source": [
    "We see that there are 27 different languages represented by `language_code` in this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b438d8-f1ee-419d-8665-2b94a3c3deaf",
   "metadata": {},
   "source": [
    "To feed this into a machine learning model, we want to [one-hot encode](https://en.wikipedia.org/wiki/One-hot) this catagorical column to a set of binary features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e817ea-5b64-4ea6-bd1b-21e8b73d92bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_df = pd.get_dummies(df, columns=\"language_code\")\n",
    "encoded_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb61a1d-7453-4996-bba1-d503027f2b98",
   "metadata": {},
   "source": [
    "We select out only the columns with names matching \"language\". This leaves us with all the converted binary columns, which is often referred to as the indicator matrix. This can be an input to a machine learning model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acd2087-4127-47b6-8d8b-c3182c5700ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "indicator_matrix= encoded_df.filter(regex=\"language\")\n",
    "indicator_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1d6204-cb95-479b-8979-72a215d49fc2",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468ef8db-786d-4e92-89b8-0034dcd6cb2c",
   "metadata": {},
   "source": [
    "In this tutorial, we saw how you can get started in running common data science operations in pandas directly on the `PONDER_BOOK` table in your BigQuery.\n",
    "\n",
    "That means that every single operation that you performed in this tutorial is being executed directly in your data warehouse! The only data that is being pulled out of the warehouse is the few lines of results that is printed in the notebook!\n",
    "\n",
    "Note that if you were to write the equivalent SQL query to run these pandas commands on BigQuery, it would take many lines of code to express the same query. If you're interested in learning about why, check out this [blogpost](https://ponder.io/pandas-vs-sql-part-2-pandas-is-more-concise/#:~:text=the%20window%20function.-,Conclusion,and%20dropping%20sparsely%20populated%20features.).\n",
    "\n",
    "In our next tutorial, we will share more details on how Ponder works and how you can leverage Ponder to scale up your data science workflow!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
