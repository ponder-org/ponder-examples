{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98b117c8-51b2-4a7c-acac-5db439945586",
   "metadata": {},
   "source": [
    "# Tutorial 3: Connecting to Your Data Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd606f0d-37ba-4f91-9514-41653e6482cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os; os.chdir(\"..\")\n",
    "import credential\n",
    "import ponder.bigquery\n",
    "import modin.pandas as pd\n",
    "bigquery_con = ponder.bigquery.connect(user=credential.params[\"user\"],password=credential.params[\"password\"],account=credential.params[\"account\"],role=credential.params[\"role\"],database=credential.params[\"database\"],schema=credential.params[\"schema\"],warehouse=credential.params[\"warehouse\"])\n",
    "ponder.bigquery.init(bigquery_con,enable_ssl=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90cd1e5e-fd2b-4b04-9a3b-a0bf5be06240",
   "metadata": {},
   "source": [
    "Before we start can start our analysis, we need to first connect to a data source. Ponder currently supports `read_csv` for operating on CSV files and `read_sql` for operating on tables that are already stored in BigQuery."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2caaf89-7c98-47d6-b4b1-e7dc07318762",
   "metadata": {},
   "source": [
    "<img src=\"https://docs.ponder.io/_images/architecture.png\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511071e4-0121-45fc-8fe0-6574609f61b5",
   "metadata": {},
   "source": [
    "## ``read_sql:``Working with existing tables\n",
    "\n",
    "To work with data stored in an existing table in BigQuery, we use the ``read_sql`` command and provide the name of the table ``PONDER_CUSTOMER`` and pass in ``auto`` to the connection parameter to auto-populate the connection information based on what we provided earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c3f33a-c621-4bf1-b2c2-01b05531fb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql(\"PONDER_CUSTOMER\", bigquery_con)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8c4d0e-c38b-4f62-a87f-8155ac869dfc",
   "metadata": {},
   "source": [
    "Now that we have a Ponder DataFrame that points to the ``PONDER_CUSTOMER`` table in your data warehouse, you can now work on your DataFrame ``df`` just like you would typically do with any pandas dataframe – with all the computation happening on your warehouse!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3a73e8-54e8-4ff8-bdcd-6ade394e33ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fadeace-bb12-4ba2-82a5-f205b30cc39e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> <b>Note: </b> <span> Unlike in pandas, the data ingestion (read_*) command in Ponder does not actually load in the data into a dataframe in memory. Instead, you can think of the Ponder DataFrame acting as a pointer to the table in BigQuery that stores the data and relays all the operations to be performed on the tables in BigQuery. </span></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e41980-4ecc-4b0a-abd2-14ddd66c6724",
   "metadata": {},
   "source": [
    "## ``read_csv:`` Working with CSV files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafb3e0e-4ed0-4b7b-a62f-2512689b6a5f",
   "metadata": {},
   "source": [
    "### Working with remote CSV files\n",
    "To work with ``CSV`` files, use the ``read_csv`` command to feed in the filepath to the CSV file. If the filepath is a remote path to the CSV (e.g., filepath to S3, GCS, or a public dataset URL), you can enter the path directly as follow. Ponder will automatically process your CSV file and load it into a temporary table in your data warehouse account for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c727d98-c1e2-4065-8243-dc723c908a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://github.com/ponder-org/ponder-datasets/blob/main/tpch/orders.csv?raw=True\", header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96659862-0482-440f-a433-a81270e92d50",
   "metadata": {},
   "source": [
    "Now that your data is loaded into a temporary table in your data warehouse and Ponder DataFrame is pointing to the table, you can now work on your DataFrame ``df`` just like you would typically do with any pandas dataframe – with all the computation happening on your warehouse!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d68d5ff-8b4c-424d-a761-8afe347276fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ad8d30-a5bc-48f4-ae39-e15743bc6742",
   "metadata": {},
   "source": [
    "### Working with your own local CSV files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aceb50df-7f41-48b1-9cf7-08e1173346f0",
   "metadata": {},
   "source": [
    "If you have a CSV file locally that you want to analyze with Ponder, we provide an interface that allows you to stage the file for analysis.\n",
    "\n",
    "**1. Uploading to Ponder:** If you have a CSV file on your local machine, you must first upload them through the notebook interface. You can upload files to your Jupyter directory using the file upload functionality provided by Jupyter notebook.\n",
    "\n",
    "<img src=\"https://docs.ponder.io/_images/upload2.png\" width=\"50%\"></img>\n",
    "\n",
    "**2. Staging CSV file to a remote path:** After uploading your files to the Jupyter directory, you will need to stage the file to a remote path so that it is accessible by read_csv, as following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bee4ea-8c92-4426-a34a-fbd34206b696",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!wget -q \"https://raw.githubusercontent.com/ponder-org/ponder-datasets/main/movies.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ae409a-e682-4c39-bc86-7be77cbaf9bc",
   "metadata": {},
   "source": [
    "or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8563d4f-4253-4ed7-b58b-57717dfa3b33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!curl \"https://raw.githubusercontent.com/ponder-org/ponder-datasets/main/movies.csv\" > movies.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d863b9cd-40ba-4a81-8a7d-8f9c0b5819c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ponder.utils.core import Teleporter\n",
    "t = Teleporter()\n",
    "remote_path = t.depulso(\"movies.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c66eba-a566-45d0-b334-5609a71ba88f",
   "metadata": {},
   "source": [
    "**3. Read your CSV file with ``read_csv``**: Once the file is staged to the remote_path, you can load it in via `pd.read_csv` as usual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1f7bad-29ec-4578-8f08-5a7be51783c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(remote_path, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be633e30-bb1d-4ac9-8873-0a155c692f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
